{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c30f38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "from textblob import Word\n",
    "import nltk\n",
    "from gensim import corpora, models\n",
    "from gensim.models import CoherenceModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b60790e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_excel('318NewsDataSet.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e43706",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.columns = [col.strip().replace(' ', '_') for col in df.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ae6ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stopwords = set(nltk.corpus.stopwords.words('english')).union({\n",
    "    'said', 'also', 'sh', 'r', 'one', 'would', 'get', 'could', 'us',\n",
    "    'like', 'make', 'many', 'however', 'must', 'still', 'even', 'much', 'new', 'take',\n",
    "    'two', 'use', 'may', 'well', 'back', 'around', 'another', 'since', 'year', 'yet',\n",
    "    'without', 'first', 'mr', 'can'\n",
    "})\n",
    "\n",
    "def preprocess(text):\n",
    "    text = str(text).lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation + string.digits))\n",
    "    words = text.split()\n",
    "    words = [Word(w).lemmatize() for w in words if w not in stopwords]\n",
    "    return ' '.join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9391ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Processed_Content'] = df['Content'].apply(preprocess)\n",
    "df['Tokens'] = df['Processed_Content'].apply(lambda x: x.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6563e1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Doc_Length'] = df['Tokens'].apply(len)\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df['Doc_Length'], bins=30, kde=True)\n",
    "plt.title('Document Length Distribution')\n",
    "plt.xlabel('Word Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.savefig(\"length_distribution.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e80321",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dictionary = corpora.Dictionary(df['Tokens'])\n",
    "corpus = [dictionary.doc2bow(text) for text in df['Tokens']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ae2d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "coherence_scores = []\n",
    "models_list = []\n",
    "for num_topics in range(2, 11):\n",
    "    lda_model = models.LdaModel(corpus=corpus,\n",
    "                                 id2word=dictionary,\n",
    "                                 num_topics=num_topics,\n",
    "                                 random_state=42,\n",
    "                                 update_every=1,\n",
    "                                 chunksize=100,\n",
    "                                 passes=10,\n",
    "                                 alpha='auto',\n",
    "                                 per_word_topics=True)\n",
    "    coherence_model = CoherenceModel(model=lda_model, texts=df['Tokens'], dictionary=dictionary, coherence='c_v')\n",
    "    score = coherence_model.get_coherence()\n",
    "    coherence_scores.append(score)\n",
    "    models_list.append(lda_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54aabf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(2, 11), coherence_scores, marker='o')\n",
    "plt.title('LDA Coherence Scores')\n",
    "plt.xlabel('Number of Topics')\n",
    "plt.ylabel('Coherence Score')\n",
    "plt.grid(True)\n",
    "plt.savefig(\"coherence_scores.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d070706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_model = models_list[4]  # Adjust based on coherence score results\n",
    "topics = best_model.print_topics(num_words=10)\n",
    "for topic_num, topic in topics:\n",
    "    print(f\"Topic {topic_num}: {topic}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d532274",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_dominant_topic(ldamodel, bow):\n",
    "    topics = ldamodel.get_document_topics(bow)\n",
    "    if topics:\n",
    "        return sorted(topics, key=lambda x: x[1], reverse=True)[0][0]\n",
    "    return None\n",
    "\n",
    "df['Dominant_Topic'] = [get_dominant_topic(best_model, doc) for doc in corpus]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afa15c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_csv(\"topic_model_output.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
